<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>William Thong</title>
  
  <meta name="author" content="William Thong">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<!-- <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>"> -->
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:10px">
      <td style="padding:10px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:10px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:left">
              <post-title>William <bold>Thong<bold></post-title><br><br>
              </p>
              <p>I am a research scientist at <a href="https://ai.sony" target="\_blank">Sony AI</a>, focusing on algorithmic fairness in computer vision.
              </p>
              <p>I did my PhD at the <a href="https://ivi.fnwi.uva.nl/vislab/" target="\_blank">Video & Image Sense</a> lab of the <a href="https://www.uva.nl/en" target="\_blank">University of Amsterdam</a>, under the supervision of <a href="http://www.ceessnoek.info/" target="\_blank">Cees Snoek</a>. My PhD dissertation involved visual similarity, learning with limited labels, and model biases.
              </p>
              <p>Previously, I received a B.Eng. and an M.Sc. in Biomedical Engineering from <a href="https://www.polymtl.ca/en/" target="\_blank">Polytechnique Montr&eacute;al</a>, and an M.Sc. in Bioimaging from <a href="https://www.telecom-paris.fr/en/home" target="\_blank">T&eacute;l&eacute;com Paris</a>.
              I completed my Master's thesis under the supervision of
              <a href="https://www.polymtl.ca/expertises/en/kadoury-samuel" target="\_blank">Samuel Kadoury</a>
              (<a href="https://www.polymtl.ca/medical/en/" target="\_blank">MedICAL lab</a>) and
              <a href="https://sites.google.com/view/christopher-pal" target="\_blank">Chris Pal</a>
              (<a href="https://mila.quebec/en/" target="\_blank">Mila</a>)
              on the classification of biomedical images with deep learning.
              </p>
              <p style="text-align:left">
                [<a href="mailto:william.thong@sony.com">Email</a>] &nbsp
                [<a href="https://ch.linkedin.com/in/twuilliam">LinkedIn</a>] &nbsp
                [<a href="https://scholar.google.nl/citations?user=CPuz5p4AAAAJ&hl">Google Scholar</a>] &nbsp
                [<a href="https://twitter.com/twuilliam">Twitter</a>] &nbsp
                [<a href="https://github.com/twuilliam">Github</a>]
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <img style="width:100%;max-width:100%" alt="profile photo" src="images/wt-circle.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:10px;width:100%;vertical-align:middle">
              <heading>Conference &amp; Journal publicatons</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:10px;width:25%;vertical-align:top">
              <img src="images/thong2021diverse.png" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://doi.org/10.1145/3461646">
                <papertitle>Diversely-Supervised Visual Product Search</papertitle>
              </a>
              <br>
              <strong>William Thong</strong> and
              Cees G. M. Snoek
              <br>
              <em>ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM)</em>, 2022
              <br>
              [<a href="https://doi.org/10.1145/3461646">paper</a>]&nbsp;
              [<a href="javascript:void(0)">arxiv</a>]&nbsp;
              [<a href="https://github.com/twuilliam/diverse-search">code</a>]&nbsp;
              <p>We create a diverse set of labels from instance, attribute and category similarities for visual product search.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:10px;width:25%;vertical-align:top">
              <img src="images/thong2021bias.png" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2110.14336">
                <papertitle>Feature and Label Embedding Spaces Matter in Addressing Image Classifier Bias</papertitle>
              </a>
              <br>
              <strong>William Thong</strong>,
              Cees G. M. Snoek
              <br>
              <em>British Machine Vision Conference (BMVC)</em>, 2021
              <br>
              [<a href="https://www.bmvc2021-virtualconference.com/assets/papers/0180.pdf">paper</a>]&nbsp;
              [<a href="https://arxiv.org/abs/2110.14336">arxiv</a>]&nbsp;
              [<a href="https://github.com/twuilliam/bias-classifiers">code</a>]&nbsp;
              <p>
              We identify and mitigate biases in both feature and label embedding spaces in image classifiers.
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:10px;width:25%;vertical-align:top">
              <img src="images/mettes2021object.png" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2104.04715">
                <papertitle>Object Priors for Classifying and Localizing Unseen Actions</papertitle>
              </a>
              <br>
              Pascal Mettes,
              <strong>William Thong</strong>,
              Cees G. M. Snoek
              <br>
              <em>International Journal of Computer Vision (IJCV)</em>, 2021
              <br>
              [<a href="https://doi.org/10.1007/s11263-021-01454-y">paper</a>]&nbsp;
              [<a href="https://arxiv.org/abs/2104.04715">arxiv</a>]&nbsp;
              [<a href="https://github.com/psmmettes/object-priors-unseen-actions">code</a>]&nbsp;
              <p>We derive spatial and semantic priors to recognize unseen actions in videos with zero training sample.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:10px;width:25%;vertical-align:top">
              <img src="images/thong2020gzsl.png" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://www.bmvc2020-conference.com/conference/papers/paper_0261.html">
                <papertitle>Bias-Awareness for Zero-Shot Learning the Seen and Unseen</papertitle>
              </a>
              <br>
              <strong>William Thong</strong> and
              Cees G. M. Snoek
              <br>
              <em>British Machine Vision Conference (BMVC)</em>, 2020
              <br>
              [<a href="https://www.bmvc2020-conference.com/assets/papers/0261.pdf">paper</a>]&nbsp;
              [<a href="https://arxiv.org/abs/2008.11185">arxiv</a>]&nbsp;
              [<a href="https://github.com/twuilliam/bias-gzsl">code</a>]&nbsp;
              [<a href="https://www.bmvc2020-conference.com/conference/papers/paper_0261.html">video</a>]&nbsp;
              <p>We mitigate the classifier bias towards classes seen during training in generalized zero-shot learning.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:10px;width:25%;vertical-align:top">
              <img src="images/thong2019open.png" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/1911.08621">
                <papertitle>Open Cross-Domain Visual Search</papertitle>
              </a>
              <br>
              <strong>William Thong</strong>, Pascal Mettes, Cees G.M. Snoek
              <br>
              <em>Computer Vision and Image Understanding (CVIU)</em>, 2020
              <br>
              [<a href="https://doi.org/10.1016/j.cviu.2020.103045">paper</a>]&nbsp;
              [<a href="https://arxiv.org/abs/1911.08621">arxiv</a>]&nbsp;
              [<a href="https://github.com/twuilliam/open-search">code</a>]&nbsp;
              <p>We search for categories from any source domain to any target domain in a common semantic space.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:10px;width:25%;vertical-align:top">
              <img src="images/turkoglu2019aaai.png" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/1902.00671">
                <papertitle>A Layer-Based Sequential Framework for Scene Generation with GANs</papertitle>
              </a>
              <br>
              Mehmet O. Turkoglu, <strong>William Thong</strong>, Luuk Spreeuwers, Berkay Kicanaoglu
              <br>
              <em>AAAI Conference on Artificial Intelligence (AAAI)</em>, 2019
              <br>
              [<a href="https://doi.org/10.1609/aaai.v33i01.33018901">paper</a>]&nbsp;
              [<a href="https://arxiv.org/abs/1902.00671">arxiv</a>]&nbsp;
              [<a href="https://drive.google.com/open?id=1MJhVce9a5jWI6GnW45k4gNFGe-Jie0-z">poster</a>]&nbsp;
              [<a href="https://github.com/0zgur0/Seq_Scene_Gen">code</a>]
              <p>We compose a scene layer-by-layer, with an explicit control over the generation of all scene elements.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:10px;width:25%;vertical-align:top">
              <img src="images/thong2018kidneys.png" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://doi.org/10.1080/21681163.2016.1148636">
                <papertitle>Convolutional Networks for Kidney Segmentation in Contrast-Enhanced CT Scans</papertitle>
              </a>
              <br>
              <strong>William Thong</strong>, Samuel Kadoury, Nicolas Pich&eacute;, Christopher J. Pal
              <br>
              <em>CMBBE: Imaging &amp; Visualization</em>, 2018
              <br>
            [<a href="https://doi.org/10.1080/21681163.2016.1148636">paper</a>] &ndash; initially presented at <a href="https://cs.adelaide.edu.au/~dlmia/index.html">MICCAI-DLMIA 2015</a>
              <p>We segment healthy and abnormal kidneys in CT scans with a patch-based ConvNet.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:10px;width:25%;vertical-align:top">
              <img src="images/thong2016spine.png" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://doi.org/10.1007/s00586-016-4426-3">
                <papertitle>Three-dimensional Morphology Study of Surgical Adolescent Idiopathic Scoliosis Patient from Encoded Geometric Models</papertitle>
              </a>
              <br>
              <strong>William Thong</strong>, Stefan Parent, James Wu, Carl-&Eacute;ric Aubin, Hubert Labelle, Samuel Kadoury
              <br>
              <em>European Spine Journal (ESJ)</em>, 2016
              <br>
              [<a href="https://doi.org/10.1007/s00586-016-4426-3">paper</a>]
              <p>We cluster scoliotic spine deformations in 3D representations with a stacked auto-encoder.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:10px;width:25%;vertical-align:top">
              <img src="images/ullmann2014vertebrae.png" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="http://dx.doi.org/10.1155/2014/719520">
                  <papertitle>Automatic Labeling of Vertebral Levels using a Robust Template-Based Approach</papertitle>
              </a>
              <br>
              Eug&eacute;nie Ullmann, Jean Fran&ccedil;ois Pelletier Paquette*, <strong>William Thong</strong>*, Julien Cohen-Adad
              <br>
              <em>International Journal of Biomedical Imaging (IJBI)</em>, 2014
              <br>
              [<a href="http://dx.doi.org/10.1155/2014/719520">paper</a>]
              <p></p>
              <p>We build a template to predict vertebral levels in MRI images.</p>
            </td>
          </tr>

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;padding-top:20px"><tbody>
            <tr>
            <td style="padding:10px;width:100%;vertical-align:middle">
              <heading>Workshop &amp; Abstract publications</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>



          <tr>
            <td style="padding:10px;width:25%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2105.03072">
                  <papertitle>NTIRE 2021 challenge on perceptual image quality assessment</papertitle>
              </a>
              <br>
              Gu et al. <em>CVPR workshops</em>, 2021.
            </td>
          </tr>

          <tr>
            <td style="padding:10px;width:25%;vertical-align:middle">
              <a href="https://doi.org/10.1145/3343031.3350597">
                  <papertitle>Interactive Exploration of Journalistic Video Footage through Multimodal Semantic Matching</papertitle>
              </a>
              <br>
              Ibrahimi et al. <em>ACM Multimedia (Demo track)</em>, 2019.
            </td>
          </tr>

          <tr>
            <td style="padding:10px;width:25%;vertical-align:middle">
              <a href="https://doi.org/10.1007/978-3-319-14148-0_2">
              <papertitle>Stacked Auto-Encoders for Classification of 3D Spine Models in Adolescent Idiopathic Scoliosis</papertitle>
              </a>
              <br>
              <strong>Thong</strong> et al. <em>MICCAI-CSI workshop</em>, 2014.
            </td>
          </tr>

          <tr>
            <td style="padding:10px;width:25%;vertical-align:middle">
              <a href="https://www.researchgate.net/publication/284653428_Spinal_Cord_Toolbox_an_open-source_framework_for_processing_spinal_cord_MRI_data">
                  <papertitle>Spinal Cord Toolbox: an Open-Source Framework for Processing Spinal Cord MRI Data</papertitle>
              </a>
              <br>
              Cohen-Adad et al. <em>OHBM</em>, 2014.
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:10px;width:100%;vertical-align:middle">
              <heading>Academic service</heading>
              <p>
              Reviewer for CVPR, ECCV, ICCV, NeurIPS, WACV, BMVC.
              </p>
              <p>
              Outstanding reviewer awards at CVPR'21 and BMVC'20 and 21.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:10px">
              <br>
              <p style="text-align:right;font-size:small;">
                Webpage template from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>.
              </p>
            </td>
          </tr>
        </tbody></table>

      </td>
    </tr>
  </table>

  <!-- Google Analytics -->
  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-131081305-1', 'auto');
  ga('send', 'pageview');
  </script>

</body>

</html>
